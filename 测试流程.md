测试流程

创建 Lucene 文本文件
在TEXT_FOLDER_PATH中，也就是lucene_texts中
比如 1.txt 2.txt 3.txt 4.txt
就直接加内容，Copacabana is a world-famous beach with golden sands and a tropical feel.

或者直接在第二个框里面直接加

然后重构rebuild index

pure lucene search
http://localhost:8080/TravelOfferSystem_war/lucene/search?query=beach


# SQL + Lucene Mixed queries
SELECT PLG_id, PLG_nom FROM Plage WHERE PLG_nom LIKE '%Beach%' with world

- part sql
SELECT PLG_id, PLG_nom FROM Plage WHERE PLG_nom LIKE '%Beach%'

1	Hillside Beach
2	Chellos Beach
3	Savoy Beach
4	Garden's Beach
5	Turtle's Beach
6	Hilton Beach
7	Seashell's Beach
8	Paradize's Beach
9	Collibri's Beach
10	Sunny Beach

- lucene part

world
1	Hillside Beach It is a world-famous beach with golden sand and tropical atmosphere.
4	Garden's Beach is famous for its luxury resorts and world-class service.

MixedQuery Results:
PK=1, score=0.3280544, SQLData=PLG_id=1; PLG_nom=Hillside Beach;
PK=4, score=0.2780032, SQLData=PLG_id=4; PLG_nom=Garden's Beach;



查询包含 "Beach" 且文本中包含 "shunshine" 的海滩
SELECT PLG_id, PLG_nom FROM Plage WHERE PLG_nom LIKE '%Beach%' with sunshine

T : sitetrouriqs mysql SIT_id + 
R ： lucene index + content

SELECT 
join T.SITid and R.index 


当我在index.jsp的Execute Mixed Query中输入Execute Mixed Query后，只能返回"No 'with' found. Just an SQL: SELECT SIT_id, SIT_description, SIT_type FROM SiteTouristique"，似乎我需要改写下代码中advancedperisistence中的实现逻辑？从而允许混合查询可以先得到普通sql的结果，也就是根据SiteTouristique的lieu_id找到Lieu表中的地点名称，根据所需的比如说在SIT_description中的rocheuse关键词找出对应的Lieu表中的地点，然后根据SiteTouristique中的SIT_id join lucene的id索引，找出lucene中的content，最终只返回Lieu地点名和lucene的content内容, 实现上述的逻辑，给出需要修改的文件的完整代码以及可以直接输入Execute Mixed Query的完整查询语句



GET http://localhost:8080/TravelOfferSystem_war/lucene/mixed?query=
SELECT s.SIT_id, s.SIT_description, s.SIT_type, l.LIE_nom
FROM SiteTouristique s
JOIN Lieu l ON s.LIE_id = l.LIE_id
WHERE s.SIT_type='historique'
with rocheuse










我现在有两层，一层dao，一层persistence
代码如下package com.traveloffersystem.dao;

import java.util.List;
import java.util.Map;

/**
 * Combined DAO Interface
 * 仅包含与 SiteTouristique 和 Lieu 表相关的数据库操作方法，以及 Lucene 扩展方法
 */
public interface CombinedDAO {

    // =========================
    // 1. 关系型数据库相关方法
    // =========================

    /**
     * 创建一个 SiteTouristique 记录
     *
     * @param siteTouristiqueData 包含 SiteTouristique 数据的 Map
     * @throws Exception
     */
    void createSiteTouristique(Map<String, Object> siteTouristiqueData) throws Exception;

    /**
     * 根据 ID 查找 SiteTouristique 记录
     *
     * @param id SIT_id
     * @return 包含 SiteTouristique 数据的 Map
     * @throws Exception
     */
    Map<String, Object> findSiteTouristiqueById(int id) throws Exception;

    /**
     * 查找所有 SiteTouristique 记录
     *
     * @return 包含多个 SiteTouristique 数据的 List
     * @throws Exception
     */
    List<Map<String, Object>> findAllSiteTouristiques() throws Exception;

    /**
     * 创建一个 Lieu 记录
     *
     * @param lieuData 包含 Lieu 数据的 Map
     * @throws Exception
     */
    void createLieu(Map<String, Object> lieuData) throws Exception;

    /**
     * 根据 ID 查找 Lieu 记录
     *
     * @param id LIE_id
     * @return 包含 Lieu 数据的 Map
     * @throws Exception
     */
    Map<String, Object> findLieuById(int id) throws Exception;

    /**
     * 查找所有 Lieu 记录
     *
     * @return 包含多个 Lieu 数据的 List
     * @throws Exception
     */
    List<Map<String, Object>> findAllLieux() throws Exception;

    // =========================
    // 2. Lucene相关方法
    // =========================

    /**
     * 向特定行添加文本
     *
     * @param id      SIT_id
     * @param content 文本内容
     * @throws Exception
     */
    void addTextFileToRow(int id, String content) throws Exception;

    /**
     * 重建 Lucene 索引
     *
     * @throws Exception
     */
    void rebuildLuceneIndex() throws Exception;

    /**
     * 执行混合查询
     *
     * @param mixedQuery 混合查询字符串
     * @return 查询结果字符串
     * @throws Exception
     */
    String executeMixedQuery(String mixedQuery) throws Exception;

    /**
     * 添加 Lucene 文档
     *
     * @param id      文档 ID
     * @param content 文档内容
     * @throws Exception
     */
    void addLuceneDocument(int id, String content) throws Exception;

    /**
     * 执行 Lucene 查询
     *
     * @param queryText 查询文本
     * @return 查询结果字符串
     * @throws Exception
     */
    String searchLucene(String queryText) throws Exception;
}
package com.traveloffersystem.persistence;

import com.traveloffersystem.dao.CombinedDAO;
import com.traveloffersystem.utils.FileTextUtils;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.*;
import org.apache.lucene.index.*;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.*;
import org.apache.lucene.store.FSDirectory;

import java.io.File;
import java.math.BigDecimal;
import java.nio.file.Paths;
import java.sql.*;
import java.util.*;

/**
 * AdvancedPersistence 实现 CombinedDAO 接口
 * 仅实现与 SiteTouristique 和 Lieu 表相关的数据库操作，以及 Lucene 的文本操作
 */
public class AdvancedPersistence implements CombinedDAO {

    // Lucene 文本文件目录
    private static final String TEXT_FOLDER_PATH =
            "C:/Users/crayo/Desktop/CY Master I/AGP/dev_version/TravelOfferSystem/lucene_texts";

    // Lucene 索引目录
    private static final String LUCENE_INDEX_PATH =
            "C:/Users/crayo/Desktop/CY Master I/AGP/dev_version/TravelOfferSystem/lucene_data";

    // =============================
    // 1) 关系型数据库相关实现
    // =============================

    @Override
    public void createSiteTouristique(Map<String, Object> siteTouristiqueData) throws Exception {
        String sql = "INSERT INTO SiteTouristique (SIT_id, SIT_description, SIT_tarif, SIT_duree, SIT_type, LIE_id) " +
                "VALUES (?, ?, ?, ?, ?, ?)";
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, (Integer) siteTouristiqueData.get("SIT_id"));
            ps.setString(2, (String) siteTouristiqueData.get("SIT_description"));
            ps.setBigDecimal(3, (BigDecimal) siteTouristiqueData.get("SIT_tarif"));
            ps.setInt(4, (Integer) siteTouristiqueData.get("SIT_duree"));
            ps.setString(5, (String) siteTouristiqueData.get("SIT_type"));
            ps.setInt(6, (Integer) siteTouristiqueData.get("LIE_id"));
            ps.executeUpdate();
        }
    }

    @Override
    public Map<String, Object> findSiteTouristiqueById(int id) throws Exception {
        String sql = "SELECT * FROM SiteTouristique WHERE SIT_id = ?";
        Map<String, Object> result = new HashMap<>();
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, id);
            ResultSet rs = ps.executeQuery();
            if (rs.next()) {
                ResultSetMetaData md = rs.getMetaData();
                for (int i = 1; i <= md.getColumnCount(); i++) {
                    result.put(md.getColumnName(i), rs.getObject(i));
                }
            }
        }
        return result.isEmpty() ? null : result;
    }

    @Override
    public List<Map<String, Object>> findAllSiteTouristiques() throws Exception {
        List<Map<String, Object>> sites = new ArrayList<>();
        String sql = "SELECT * FROM SiteTouristique";
        try (Connection conn = JdbcConnection.getConnection();
             Statement st = conn.createStatement();
             ResultSet rs = st.executeQuery(sql)) {
            ResultSetMetaData md = rs.getMetaData();
            while (rs.next()) {
                Map<String, Object> row = new HashMap<>();
                for (int i = 1; i <= md.getColumnCount(); i++) {
                    row.put(md.getColumnName(i), rs.getObject(i));
                }
                sites.add(row);
            }
        }
        return sites;
    }

    @Override
    public void createLieu(Map<String, Object> lieuData) throws Exception {
        String sql = "INSERT INTO Lieu (LIE_id, LIE_nom, LIE_type, LIE_latitude, LIE_longitude, ILE_id) " +
                "VALUES (?, ?, ?, ?, ?, ?)";
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, (Integer) lieuData.get("LIE_id"));
            ps.setString(2, (String) lieuData.get("LIE_nom"));
            ps.setString(3, (String) lieuData.get("LIE_type"));
            ps.setBigDecimal(4, (BigDecimal) lieuData.get("LIE_latitude"));
            ps.setBigDecimal(5, (BigDecimal) lieuData.get("LIE_longitude"));
            ps.setInt(6, (Integer) lieuData.get("ILE_id"));
            ps.executeUpdate();
        }
    }

    @Override
    public Map<String, Object> findLieuById(int id) throws Exception {
        String sql = "SELECT * FROM Lieu WHERE LIE_id = ?";
        Map<String, Object> result = new HashMap<>();
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, id);
            ResultSet rs = ps.executeQuery();
            if (rs.next()) {
                ResultSetMetaData md = rs.getMetaData();
                for (int i = 1; i <= md.getColumnCount(); i++) {
                    result.put(md.getColumnName(i), rs.getObject(i));
                }
            }
        }
        return result.isEmpty() ? null : result;
    }

    @Override
    public List<Map<String, Object>> findAllLieux() throws Exception {
        List<Map<String, Object>> lieux = new ArrayList<>();
        String sql = "SELECT * FROM Lieu";
        try (Connection conn = JdbcConnection.getConnection();
             Statement st = conn.createStatement();
             ResultSet rs = st.executeQuery(sql)) {
            ResultSetMetaData md = rs.getMetaData();
            while (rs.next()) {
                Map<String, Object> row = new HashMap<>();
                for (int i = 1; i <= md.getColumnCount(); i++) {
                    row.put(md.getColumnName(i), rs.getObject(i));
                }
                lieux.add(row);
            }
        }
        return lieux;
    }

    // =============================
    // 2) Lucene相关实现
    // =============================

    @Override
    public void addTextFileToRow(int id, String content) throws Exception {
        // 1) 写文件
        String filePath = TEXT_FOLDER_PATH + File.separator + id + ".txt";
        FileTextUtils.writeTextFile(filePath, content);
        // 2) 添加到 Lucene 索引
        addLuceneDocument(id, content);
    }

    @Override
    public void rebuildLuceneIndex() throws Exception {
        try (FSDirectory dir = FSDirectory.open(Paths.get(LUCENE_INDEX_PATH));
             IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(new StandardAnalyzer()))) {

            writer.deleteAll(); // 清空索引

            File folder = new File(TEXT_FOLDER_PATH);
            File[] files = folder.listFiles((dir1, name) -> name.endsWith(".txt"));
            if (files != null) {
                for (File f : files) {
                    String filename = f.getName();
                    int key = Integer.parseInt(filename.replace(".txt", ""));
                    String txt = FileTextUtils.readTextFile(f.getAbsolutePath());

                    Document doc = new Document();
                    doc.add(new IntPoint("id", key));
                    doc.add(new StoredField("id", key));
                    doc.add(new TextField("content", txt, Field.Store.YES));
                    writer.addDocument(doc);
                }
            }
            writer.commit();
        }
    }

    @Override
    public String executeMixedQuery(String mixedQuery) throws Exception {
        // 1) 判断是否包含 " with "
        String lower = mixedQuery.toLowerCase();
        int idx = lower.indexOf(" with ");
        if (idx < 0) {
            // 不是混合查询，直接执行 SQL
            return executeSimpleSQLQuery(mixedQuery);
        }

        // 2) 拆分
        String sqlPart = mixedQuery.substring(0, idx).trim();     // "SELECT ... FROM ... WHERE ..."
        String lucenePart = mixedQuery.substring(idx + 6).trim(); // Lucene 查询

        // 3) 执行 SQL 查询，获取 SIT_id 集合
        Set<Integer> sqlResultSet = new HashSet<>();
        try (Connection conn = JdbcConnection.getConnection();
             Statement st = conn.createStatement();
             ResultSet rs = st.executeQuery(sqlPart)) {

            while (rs.next()) {
                int sitId = rs.getInt(1); // 假设第一个选择的列是 SIT_id
                sqlResultSet.add(sitId);
            }
        }

        // 4) 执行 Lucene 搜索，获取 SIT_id 和分数
        Map<Integer, Float> luceneResults = new LinkedHashMap<>();
        try (FSDirectory dir = FSDirectory.open(Paths.get(LUCENE_INDEX_PATH));
             DirectoryReader reader = DirectoryReader.open(dir)) {

            IndexSearcher searcher = new IndexSearcher(reader);
            QueryParser parser = new QueryParser("content", new StandardAnalyzer());
            Query query = parser.parse(lucenePart);

            TopDocs topDocs = searcher.search(query, 100); // 获取前100条结果
            for (ScoreDoc sd : topDocs.scoreDocs) {
                Document doc = searcher.doc(sd.doc);
                int sitId = Integer.parseInt(doc.get("id"));
                float score = sd.score;
                luceneResults.put(sitId, score);
            }
        }

        // 5) 交集和排序
        List<Map.Entry<Integer, Float>> joined = new ArrayList<>();
        for (Map.Entry<Integer, Float> entry : luceneResults.entrySet()) {
            if (sqlResultSet.contains(entry.getKey())) {
                joined.add(entry);
            }
        }

        // 按分数降序排序
        joined.sort((a, b) -> Float.compare(b.getValue(), a.getValue()));

        // 6) 获取 Lieu 名称和 Lucene content
        StringBuilder sb = new StringBuilder("MixedQuery Results:\n");
        for (Map.Entry<Integer, Float> e : joined) {
            int sitId = e.getKey();
            float score = e.getValue();
            // 获取 LIE_id 通过 SIT_id
            Integer lieId = getLieIdBySitId(sitId);
            if (lieId != null) {
                Map<String, Object> lieu = findLieuById(lieId);
                if (lieu != null) {
                    String lieuNom = (String) lieu.get("LIE_nom");
                    String content = getLuceneContent(sitId);
                    sb.append("Lieu Name=").append(lieuNom)
                            .append(", Content=").append(content)
                            .append(", Score=").append(score)
                            .append("\n");
                }
            }
        }

        return sb.toString();
    }

    /**
     * 执行非混合的简单 SQL 查询
     */
    private String executeSimpleSQLQuery(String sqlQuery) throws Exception {
        StringBuilder sb = new StringBuilder("SQL Query Results:\n");
        try (Connection conn = JdbcConnection.getConnection();
             Statement st = conn.createStatement();
             ResultSet rs = st.executeQuery(sqlQuery)) {

            ResultSetMetaData md = rs.getMetaData();
            int colCount = md.getColumnCount();

            while(rs.next()) {
                for(int i=1; i<=colCount; i++) {
                    sb.append(md.getColumnName(i)).append("=").append(rs.getObject(i)).append("; ");
                }
                sb.append("\n");
            }
        }
        return sb.toString();
    }

    /**
     * 从 Lucene 索引中获取指定 ID 的内容
     */
    private String getLuceneContent(int id) throws Exception {
        try (FSDirectory dir = FSDirectory.open(Paths.get(LUCENE_INDEX_PATH));
             DirectoryReader reader = DirectoryReader.open(dir)) {

            IndexSearcher searcher = new IndexSearcher(reader);
            Query query = IntPoint.newExactQuery("id", id);
            TopDocs topDocs = searcher.search(query, 1);
            if (topDocs.totalHits.value > 0) {
                Document doc = searcher.doc(topDocs.scoreDocs[0].doc);
                return doc.get("content");
            }
        }
        return "";
    }

    /**
     * 获取 LIE_id 通过 SIT_id
     *
     * @param sitId SIT_id
     * @return LIE_id 或 null
     * @throws Exception
     */
    private Integer getLieIdBySitId(int sitId) throws Exception {
        String sql = "SELECT LIE_id FROM SiteTouristique WHERE SIT_id = ?";
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, sitId);
            ResultSet rs = ps.executeQuery();
            if (rs.next()) {
                return rs.getInt("LIE_id");
            }
        }
        return null;
    }

    @Override
    public void addLuceneDocument(int id, String content) throws Exception {
        try (FSDirectory dir = FSDirectory.open(Paths.get(LUCENE_INDEX_PATH));
             IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(new StandardAnalyzer()))) {

            // 先删除旧文档
            Query q = IntPoint.newExactQuery("id", id);
            writer.deleteDocuments(q);

            // 添加新文档
            Document doc = new Document();
            doc.add(new IntPoint("id", id));
            doc.add(new StoredField("id", id));
            doc.add(new TextField("content", content, Field.Store.YES));
            writer.addDocument(doc);

            writer.commit();
        }
    }

    @Override
    public String searchLucene(String queryText) throws Exception {
        StringBuilder sb = new StringBuilder();
        try (FSDirectory dir = FSDirectory.open(Paths.get(LUCENE_INDEX_PATH));
             DirectoryReader reader = DirectoryReader.open(dir)) {

            IndexSearcher searcher = new IndexSearcher(reader);
            QueryParser parser = new QueryParser("content", new StandardAnalyzer());
            Query query = parser.parse(queryText);

            TopDocs topDocs = searcher.search(query, 20);
            for (ScoreDoc sd : topDocs.scoreDocs) {
                Document doc = searcher.doc(sd.doc);
                sb.append("ID=").append(doc.get("id"))
                        .append(", content=").append(doc.get("content"))
                        .append(", score=").append(sd.score)
                        .append("\n");
            }
        }
        return sb.toString();
    }
}
package com.traveloffersystem.persistence;

import com.traveloffersystem.dao.CombinedDAO;

import java.io.File;

public class BDeAPI {

    private CombinedDAO combinedDAO;
    private String tableName;
    private String keyAttribute;
    private String directoryPath;
    private String luceneIndexPath;

    public BDeAPI(CombinedDAO combinedDAO) {
        this.combinedDAO = combinedDAO;
    }

    public void declareTable(String tableName, String keyAttribute, String directoryPath) {
        this.tableName = tableName;
        this.keyAttribute = keyAttribute;
        this.directoryPath = directoryPath;
        this.luceneIndexPath = directoryPath + File.separator + "luceneIndex";

        File folder = new File(directoryPath);
        if (!folder.exists()) {
            folder.mkdirs();
        }
        File idxFolder = new File(luceneIndexPath);
        if(!idxFolder.exists()) {
            idxFolder.mkdirs();
        }
    }

    public void addText(String key, String text) throws Exception {
        int intKey = Integer.parseInt(key);
        combinedDAO.addTextFileToRow(intKey, text);
    }

    public void createTextIndex() throws Exception {
        combinedDAO.rebuildLuceneIndex();
    }

    public String executeMixedQuery(String mixedQuery) throws Exception {
        return combinedDAO.executeMixedQuery(mixedQuery);
    }

    public String executeSqlQuery(String sqlQuery) throws Exception {
        return combinedDAO.executeMixedQuery(sqlQuery);
    }

    public String executeTextQuery(String textQuery) throws Exception {
        return combinedDAO.searchLucene(textQuery);
    }
}
package com.traveloffersystem.persistence;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.SQLException;

public class JdbcConnection {
    private static final String host = "mysql-maariaa.alwaysdata.net";
    private static final String base = "maariaa_agp";
    private static final String user = "maariaa";
    private static final String password = "Ma?15102002";
//    private static final String url = "jdbc:mysql://" + host + ":3306/" + base + "?useUnicode=true&characterEncoding=UTF-8&serverTimezone=UTC";
    private static final String url = "jdbc:mariadb://mysql-maariaa.alwaysdata.net:3306/maariaa_agp"
        + "?useUnicode=true&characterEncoding=UTF-8";

    public static Connection getConnection() throws ClassNotFoundException {


        Connection connection = null;
        try {
            Class.forName("org.mariadb.jdbc.Driver");
            String url = "jdbc:mariadb://mysql-maariaa.alwaysdata.net:3306/maariaa_agp?useUnicode=true&characterEncoding=UTF-8";
            connection = DriverManager.getConnection(url, user, password);
            System.out.println("Connection established successfully!");
        } catch (ClassNotFoundException e) {
            System.err.println("MySQL Driver not found: " + e.getMessage());
        } catch (SQLException e) {
            System.err.println("Connection failed: " + e.getMessage());
            System.err.println("SQLState: " + e.getSQLState());
            System.err.println("ErrorCode: " + e.getErrorCode());
        }

        return connection;
    }
}package com.traveloffersystem.persistence;

import java.math.BigDecimal;
import java.sql.*;
import java.util.*;

public class OperatorJdbc {

    public void createSiteTouristique(Map<String, Object> siteTouristiqueData) throws Exception {
        String sql = "INSERT INTO SiteTouristique (SIT_id, SIT_description, SIT_tarif, SIT_duree, SIT_type, LIE_id) " +
                "VALUES (?, ?, ?, ?, ?, ?)";
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, (Integer) siteTouristiqueData.get("SIT_id"));
            ps.setString(2, (String) siteTouristiqueData.get("SIT_description"));
            ps.setBigDecimal(3, (BigDecimal) siteTouristiqueData.get("SIT_tarif"));
            ps.setInt(4, (Integer) siteTouristiqueData.get("SIT_duree"));
            ps.setString(5, (String) siteTouristiqueData.get("SIT_type"));
            ps.setInt(6, (Integer) siteTouristiqueData.get("LIE_id"));
            ps.executeUpdate();
        }
    }

    public Map<String, Object> findSiteTouristiqueById(int id) throws Exception {
        String sql = "SELECT * FROM SiteTouristique WHERE SIT_id = ?";
        Map<String, Object> result = new HashMap<>();
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, id);
            ResultSet rs = ps.executeQuery();
            if (rs.next()) {
                ResultSetMetaData md = rs.getMetaData();
                for (int i = 1; i <= md.getColumnCount(); i++) {
                    result.put(md.getColumnName(i), rs.getObject(i));
                }
            }
        }
        return result.isEmpty() ? null : result;
    }

    public List<Map<String, Object>> findAllSiteTouristiques() throws Exception {
        List<Map<String, Object>> sites = new ArrayList<>();
        String sql = "SELECT * FROM SiteTouristique";
        try (Connection conn = JdbcConnection.getConnection();
             Statement st = conn.createStatement();
             ResultSet rs = st.executeQuery(sql)) {
            ResultSetMetaData md = rs.getMetaData();
            while (rs.next()) {
                Map<String, Object> row = new HashMap<>();
                for (int i = 1; i <= md.getColumnCount(); i++) {
                    row.put(md.getColumnName(i), rs.getObject(i));
                }
                sites.add(row);
            }
        }
        return sites;
    }

    public void createLieu(Map<String, Object> lieuData) throws Exception {
        String sql = "INSERT INTO Lieu (LIE_id, LIE_nom, LIE_type, LIE_latitude, LIE_longitude, ILE_id) " +
                "VALUES (?, ?, ?, ?, ?, ?)";
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, (Integer) lieuData.get("LIE_id"));
            ps.setString(2, (String) lieuData.get("LIE_nom"));
            ps.setString(3, (String) lieuData.get("LIE_type"));
            ps.setBigDecimal(4, (BigDecimal) lieuData.get("LIE_latitude"));
            ps.setBigDecimal(5, (BigDecimal) lieuData.get("LIE_longitude"));
            ps.setInt(6, (Integer) lieuData.get("ILE_id"));
            ps.executeUpdate();
        }
    }

    public Map<String, Object> findLieuById(int id) throws Exception {
        String sql = "SELECT * FROM Lieu WHERE LIE_id = ?";
        Map<String, Object> result = new HashMap<>();
        try (Connection conn = JdbcConnection.getConnection();
             PreparedStatement ps = conn.prepareStatement(sql)) {
            ps.setInt(1, id);
            ResultSet rs = ps.executeQuery();
            if (rs.next()) {
                ResultSetMetaData md = rs.getMetaData();
                for (int i = 1; i <= md.getColumnCount(); i++) {
                    result.put(md.getColumnName(i), rs.getObject(i));
                }
            }
        }
        return result.isEmpty() ? null : result;
    }

    public List<Map<String, Object>> findAllLieux() throws Exception {
        List<Map<String, Object>> lieux = new ArrayList<>();
        String sql = "SELECT * FROM Lieu";
        try (Connection conn = JdbcConnection.getConnection();
             Statement st = conn.createStatement();
             ResultSet rs = st.executeQuery(sql)) {
            ResultSetMetaData md = rs.getMetaData();
            while (rs.next()) {
                Map<String, Object> row = new HashMap<>();
                for (int i = 1; i <= md.getColumnCount(); i++) {
                    row.put(md.getColumnName(i), rs.getObject(i));
                }
                lieux.add(row);
            }
        }
        return lieux;
    }

    public Set<Integer> executeSQLAndGetSitIds(String sql) throws Exception {
        Set<Integer> sitIds = new HashSet<>();
        try (Connection conn = JdbcConnection.getConnection();
             Statement st = conn.createStatement();
             ResultSet rs = st.executeQuery(sql)) {
            while (rs.next()) {
                sitIds.add(rs.getInt(1));
            }
        }
        return sitIds;
    }
}
package com.traveloffersystem.persistence;

import com.traveloffersystem.utils.FileTextUtils;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.*;
import org.apache.lucene.index.*;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.*;
import org.apache.lucene.store.FSDirectory;

import java.io.File;
import java.nio.file.Paths;

public class OperatorLucene {

    private String textFolderPath;
    private String luceneIndexPath;

    public OperatorLucene(String textFolderPath, String luceneIndexPath) {
        this.textFolderPath = textFolderPath;
        this.luceneIndexPath = luceneIndexPath;
    }

    public void addTextFileToRow(int id, String content) throws Exception {
        String filePath = textFolderPath + File.separator + id + ".txt";
        FileTextUtils.writeTextFile(filePath, content);
        addLuceneDocument(id, content);
    }

    public void addLuceneDocument(int id, String content) throws Exception {
        try (FSDirectory dir = FSDirectory.open(Paths.get(luceneIndexPath));
             IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(new StandardAnalyzer()))) {
            Query q = IntPoint.newExactQuery("id", id);
            writer.deleteDocuments(q);
            Document doc = new Document();
            doc.add(new IntPoint("id", id));
            doc.add(new StoredField("id", id));
            doc.add(new TextField("content", content, Field.Store.YES));
            writer.addDocument(doc);
            writer.commit();
        }
    }

    public void rebuildLuceneIndex() throws Exception {
        try (FSDirectory dir = FSDirectory.open(Paths.get(luceneIndexPath));
             IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(new StandardAnalyzer()))) {
            writer.deleteAll();
            File folder = new File(textFolderPath);
            File[] files = folder.listFiles((dir1, name) -> name.endsWith(".txt"));
            if (files != null) {
                for (File f : files) {
                    String filename = f.getName();
                    int key = Integer.parseInt(filename.replace(".txt", ""));
                    String txt = FileTextUtils.readTextFile(f.getAbsolutePath());
                    Document doc = new Document();
                    doc.add(new IntPoint("id", key));
                    doc.add(new StoredField("id", key));
                    doc.add(new TextField("content", txt, Field.Store.YES));
                    writer.addDocument(doc);
                }
            }
            writer.commit();
        }
    }

    public String searchLucene(String queryText) throws Exception {
        StringBuilder sb = new StringBuilder();
        try (FSDirectory dir = FSDirectory.open(Paths.get(luceneIndexPath));
             DirectoryReader reader = DirectoryReader.open(dir)) {
            IndexSearcher searcher = new IndexSearcher(reader);
            QueryParser parser = new QueryParser("content", new StandardAnalyzer());
            Query query = parser.parse(queryText);
            TopDocs topDocs = searcher.search(query, 20);
            for (ScoreDoc sd : topDocs.scoreDocs) {
                Document doc = searcher.doc(sd.doc);
                sb.append("ID=").append(doc.get("id"))
                        .append(", content=").append(doc.get("content"))
                        .append(", score=").append(sd.score)
                        .append("\n");
            }
        }
        return sb.toString();
    }

    public String getLuceneContent(int id) throws Exception {
        StringBuilder sb = new StringBuilder();
        try (FSDirectory dir = FSDirectory.open(Paths.get(luceneIndexPath));
             DirectoryReader reader = DirectoryReader.open(dir)) {
            IndexSearcher searcher = new IndexSearcher(reader);
            Query query = IntPoint.newExactQuery("id", id);
            TopDocs topDocs = searcher.search(query, 1);
            if (topDocs.totalHits.value > 0) {
                Document doc = searcher.doc(topDocs.scoreDocs[0].doc);
                sb.append(doc.get("content"));
            }
        }
        return sb.toString();
    }
}
package com.traveloffersystem.persistence;

import com.traveloffersystem.dao.CombinedDAO;

import java.math.BigDecimal;
import java.util.HashMap;
import java.util.Map;

/**
 * 持久层测试类
 */
public class PersistenceTest {

    public static void main(String[] args) {
        CombinedDAO dao = new AdvancedPersistence();

        try {
            // 1. 创建 Lieu 实体
            Map<String, Object> lieu1 = new HashMap<>();
            lieu1.put("LIE_id", 1);
            lieu1.put("LIE_nom", "Ros Sodyer / Rock Pool");
            lieu1.put("LIE_type", "site_touristique");
            lieu1.put("LIE_latitude", new BigDecimal("55.49221045"));
            lieu1.put("LIE_longitude", new BigDecimal("-4.78093258"));
            lieu1.put("ILE_id", 1);

            Map<String, Object> lieu2 = new HashMap<>();
            lieu2.put("LIE_id", 2);
            lieu2.put("LIE_nom", "Anse Forbans Beach");
            lieu2.put("LIE_type", "site_touristique");
            lieu2.put("LIE_latitude", new BigDecimal("55.52427935"));
            lieu2.put("LIE_longitude", new BigDecimal("-4.77474792"));
            lieu2.put("ILE_id", 1);

            Map<String, Object> lieu3 = new HashMap<>();
            lieu3.put("LIE_id", 3);
            lieu3.put("LIE_nom", "Mont Sebert viewpoint");
            lieu3.put("LIE_type", "site_touristique");
            lieu3.put("LIE_latitude", new BigDecimal("55.50361046"));
            lieu3.put("LIE_longitude", new BigDecimal("-4.67887615"));
            lieu3.put("ILE_id", 1);

            dao.createLieu(lieu1);
            dao.createLieu(lieu2);
            dao.createLieu(lieu3);

            System.out.println("Lieu 实体创建成功！");

            // 2. 创建 SiteTouristique 实体
            Map<String, Object> site1 = new HashMap<>();
            site1.put("SIT_id", 1);
            site1.put("SIT_description", "Une piscine rocheuse entourée de rochers.");
            site1.put("SIT_tarif", new BigDecimal("10.00"));
            site1.put("SIT_duree", 90);
            site1.put("SIT_type", "site_activite");
            site1.put("LIE_id", 1);

            Map<String, Object> site2 = new HashMap<>();
            site2.put("SIT_id", 2);
            site2.put("SIT_description", "Une plage de sable fin avec des formations rocheuses.");
            site2.put("SIT_tarif", new BigDecimal("20.00"));
            site2.put("SIT_duree", 90);
            site2.put("SIT_type", "site_historique");
            site2.put("LIE_id", 2);

            Map<String, Object> site3 = new HashMap<>();
            site3.put("SIT_id", 3);
            site3.put("SIT_description", "Un point de vue offrant une vue rocheuse spectaculaire.");
            site3.put("SIT_tarif", new BigDecimal("15.00"));
            site3.put("SIT_duree", 90);
            site3.put("SIT_type", "site_historique");
            site3.put("LIE_id", 3);

            dao.createSiteTouristique(site1);
            dao.createSiteTouristique(site2);
            dao.createSiteTouristique(site3);

            System.out.println("SiteTouristique 实体创建成功！");

            // 3. 添加文本内容到 SiteTouristique
            dao.addTextFileToRow(1, (String) site1.get("SIT_description"));
            dao.addTextFileToRow(2, (String) site2.get("SIT_description"));
            dao.addTextFileToRow(3, (String) site3.get("SIT_description"));

            System.out.println("文本内容添加成功！");

            // 4. 重建 Lucene 索引
            dao.rebuildLuceneIndex();
            System.out.println("Lucene 索引重建成功！");

            // 5. 执行混合查询
            String mixedQuery = "SELECT SIT_id FROM SiteTouristique WHERE SIT_type='site_historique' WITH rocheuse";
            String results = dao.executeMixedQuery(mixedQuery);
            System.out.println(results);

            // 6. 执行纯 SQL 查询（不包含 with 子句）
            String pureSQL = "SELECT SIT_id FROM SiteTouristique WHERE SIT_tarif > 10";
            String pureSQLResults = dao.executeMixedQuery(pureSQL);
            System.out.println(pureSQLResults);

            // 7. 执行纯 Lucene 查询（不包含 with 子句）
            String pureLuceneQuery = "rocheuse";
            String pureLuceneResults = dao.searchLucene(pureLuceneQuery);
            System.out.println("Pure Lucene Query Results:\n" + pureLuceneResults);

        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
但是我使用测试类的时候报错C:\Users\crayo\.jdks\corretto-1.8.0_442\bin\java.exe "-javaagent:C:\Program Files\JetBrains\IntelliJ IDEA 2024.2.1\lib\idea_rt.jar=65495:C:\Program Files\JetBrains\IntelliJ IDEA 2024.2.1\bin" -Dfile.encoding=UTF-8 -classpath "C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\charsets.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\access-bridge-64.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\cldrdata.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\dnsns.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\jaccess.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\jfxrt.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\localedata.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\nashorn.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\sunec.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\sunjce_provider.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\sunmscapi.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\sunpkcs11.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\ext\zipfs.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\jce.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\jfr.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\jfxswt.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\jsse.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\management-agent.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\resources.jar;C:\Users\crayo\.jdks\corretto-1.8.0_442\jre\lib\rt.jar;C:\Users\crayo\Desktop\CY Master I\AGP\dev_version\TravelOfferSystem\target\classes;C:\Users\crayo\.m2\repository\org\springframework\spring-core\5.3.29\spring-core-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-jcl\5.3.29\spring-jcl-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-beans\5.3.29\spring-beans-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-context\5.3.29\spring-context-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-aop\5.3.29\spring-aop-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-expression\5.3.29\spring-expression-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-web\5.3.29\spring-web-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-webmvc\5.3.29\spring-webmvc-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-jdbc\5.3.29\spring-jdbc-5.3.29.jar;C:\Users\crayo\.m2\repository\org\springframework\spring-tx\5.3.29\spring-tx-5.3.29.jar;C:\Users\crayo\.m2\repository\org\apache\lucene\lucene-core\8.11.2\lucene-core-8.11.2.jar;C:\Users\crayo\.m2\repository\org\apache\lucene\lucene-queryparser\8.11.2\lucene-queryparser-8.11.2.jar;C:\Users\crayo\.m2\repository\org\apache\lucene\lucene-queries\8.11.2\lucene-queries-8.11.2.jar;C:\Users\crayo\.m2\repository\org\apache\lucene\lucene-sandbox\8.11.2\lucene-sandbox-8.11.2.jar;C:\Users\crayo\.m2\repository\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\Users\crayo\.m2\repository\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\Users\crayo\.m2\repository\javax\annotation\javax.annotation-api\1.3.2\javax.annotation-api-1.3.2.jar;C:\Users\crayo\.m2\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;C:\Users\crayo\.m2\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;C:\Users\crayo\.m2\repository\ch\qos\logback\logback-classic\1.2.11\logback-classic-1.2.11.jar;C:\Users\crayo\.m2\repository\ch\qos\logback\logback-core\1.2.11\logback-core-1.2.11.jar;C:\Users\crayo\.m2\repository\javax\servlet\jstl\1.2\jstl-1.2.jar;C:\Users\crayo\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\crayo\.m2\repository\org\mariadb\jdbc\mariadb-java-client\3.1.4\mariadb-java-client-3.1.4.jar;C:\Users\crayo\.m2\repository\com\github\waffle\waffle-jna\3.2.0\waffle-jna-3.2.0.jar;C:\Users\crayo\.m2\repository\net\java\dev\jna\jna\5.12.1\jna-5.12.1.jar;C:\Users\crayo\.m2\repository\net\java\dev\jna\jna-platform\5.12.1\jna-platform-5.12.1.jar;C:\Users\crayo\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.36\jcl-over-slf4j-1.7.36.jar;C:\Users\crayo\.m2\repository\com\github\ben-manes\caffeine\caffeine\2.9.3\caffeine-2.9.3.jar;C:\Users\crayo\.m2\repository\com\google\errorprone\error_prone_annotations\2.10.0\error_prone_annotations-2.10.0.jar;C:\Users\crayo\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.14.2\jackson-databind-2.14.2.jar;C:\Users\crayo\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.14.2\jackson-annotations-2.14.2.jar;C:\Users\crayo\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.14.2\jackson-core-2.14.2.jar;C:\Users\crayo\.m2\repository\mysql\mysql-connector-java\8.0.19\mysql-connector-java-8.0.19.jar;C:\Users\crayo\.m2\repository\com\google\protobuf\protobuf-java\3.6.1\protobuf-java-3.6.1.jar;C:\Users\crayo\.m2\repository\org\junit\jupiter\junit-jupiter\5.11.4\junit-jupiter-5.11.4.jar;C:\Users\crayo\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.11.4\junit-jupiter-api-5.11.4.jar;C:\Users\crayo\.m2\repository\org\opentest4j\opentest4j\1.3.0\opentest4j-1.3.0.jar;C:\Users\crayo\.m2\repository\org\junit\platform\junit-platform-commons\1.11.4\junit-platform-commons-1.11.4.jar;C:\Users\crayo\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\crayo\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.11.4\junit-jupiter-params-5.11.4.jar;C:\Users\crayo\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.11.4\junit-jupiter-engine-5.11.4.jar;C:\Users\crayo\.m2\repository\org\junit\platform\junit-platform-engine\1.11.4\junit-platform-engine-1.11.4.jar" com.traveloffersystem.persistence.PersistenceTest
Connection established successfully!
21:03:30.325 [main] DEBUG org.mariadb.jdbc.client.impl.StandardClient - execute query: INSERT INTO Lieu (LIE_id, LIE_nom, LIE_type, LIE_latitude, LIE_longitude, ILE_id) VALUES (?, ?, ?, ?, ?, ?)
21:03:30.345 [main] WARN org.mariadb.jdbc.message.server.ErrorPacket - Error: 1054-42S22: Unknown column 'LIE_latitude' in 'INSERT INTO'
java.sql.SQLSyntaxErrorException: (conn=7744131) Unknown column 'LIE_latitude' in 'INSERT INTO'
	at org.mariadb.jdbc.export.ExceptionFactory.createException(ExceptionFactory.java:282)
	at org.mariadb.jdbc.export.ExceptionFactory.create(ExceptionFactory.java:370)
	at org.mariadb.jdbc.message.ClientMessage.readPacket(ClientMessage.java:134)
	at org.mariadb.jdbc.client.impl.StandardClient.readPacket(StandardClient.java:872)
	at org.mariadb.jdbc.client.impl.StandardClient.readResults(StandardClient.java:811)
	at org.mariadb.jdbc.client.impl.StandardClient.readResponse(StandardClient.java:730)
	at org.mariadb.jdbc.client.impl.StandardClient.execute(StandardClient.java:654)
	at org.mariadb.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:95)
	at org.mariadb.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:334)
	at org.mariadb.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:311)
	at com.traveloffersystem.persistence.AdvancedPersistence.createLieu(AdvancedPersistence.java:101)
	at com.traveloffersystem.persistence.PersistenceTest.main(PersistenceTest.java:43)

进程已结束，退出代码为 0
我需要完成的所有操作如下3.2 Partie Bases de Données Avancées (BDA) 
Une base de données relationnelle étendue 
Pour la partie BDA de votre projet, l’objectif est de construire une extension d’une BD relationnelle, qui, en 
plus de répondre à des requêtes SQL, puisse aussi traiter des requêtes portant sur du contenu textuel. Cette 
extension doit s’appuyer sur une BD relationnelle à votre choix (MySQL, Oracle, etc.) et sur le moteur 
d’indexation textuelle Lucene (http://lucene.apache.org/). 
Votre application doit utiliser cette base de données étendue (BDe), qui sera implémentée sous la forme 
d’une API, à concevoir. Pour simplifier, on va considérer que seulement une des tables de la base (appelons
la T) peut avoir une information textuelle associée à chaque ligne. Cette information ne sera pas stockée 
dans la table, mais dans des fichiers texte placés dans un répertoire R du disque. Plus précisément, pour 
une ligne de clé c de la table T à laquelle on associe un texte t, on créera dans le répertoire R un fichier de 
nom c contenant le texte t. 
L’API de la BDe devra supporter au moins les fonctionnalités suivantes : 
✓ Déclarer le nom de la table T et de son attribut clé, ainsi que le nom du répertoire R où seront placés 
les fichiers texte. 
✓ Ajouter un texte t à la ligne de clé c de la table T, en créant le fichier associé dans R. 
✓ Créer sur disque l’index textuel Lucene sur les documents du répertoire R. 
✓ Répondre à des requêtes sur la BDe, en adoptant le style JDBC (itération dans les résultats). 
Types de requêtes 
Les requêtes sur la BDe peuvent être de deux types : 
✓ Requêtes SQL « normales », sans partie textuelle. Elles seront traitées de façon classique, à travers 
JDBC, sur la base de données relationnelle. 
✓ Requêtes mixtes SQL-texte, contenant une clause supplémentaire with, qui décrit la partie textuelle 
de la requête. Elles seront traitées en combinant l’action de la BD relationnelle et du moteur 
d’indexation textuelle Lucene. 
Par exemple, dans le contexte d’une application touristique, la requête 
select nom from Site 
where type='historique'  
with sculpture Renaissance 
demande le nom des destinations touristiques de type historique, dont la description textuelle parle de 
sculpture et/ou de Renaissance.  
La requête textuelle de la clause with respecte la syntaxe de Lucene (voir la description de cette syntaxe 
ici :https://lucene.apache.org/core/10_1_0/queryparser/org/apache/lucene/queryparser/classic/package
summary.html#package.description). A la différence des requêtes SQL classiques, à chaque résultat est associé 
un score de pertinence. Les résultats des requêtes textuelles sont triés par ordre décroissant de la 
pertinence, par exemple un texte contenant les deux mots recherchés sera en principe plus pertinent qu’un 
texte qui ne contient qu’un seul des deux mots. Une requête mixte devra retourner les résultats triés par 
ordre décroissant de la pertinence textuelle et donner accès au score de chaque résultat.  
Traitement des requêtes mixtes 
Une requête est une chaine de caractères ; la requête est mixte si l’on trouve une clause with dans cette 
chaine. La requête mixte doit être décomposée en une partie SQL et une partie textuelle. 
6 
CY Cergy Paris Université, Master IISC 1ère Année                                                                    
Atelier de Gestion de Projet 
On considérera deux types de plans d’exécution possibles : 
1. On exécute séparément la partie SQL et la partie textuelle de la requête, ensuite on combine les deux 
résultats en les joignant sur la clé de la table T. Comme le lien entre le résultat SQL et le résultat textuel 
se fait à travers la clé de T, il faudra donc rajouter la clé de T dans la clause select de la partie SQL de 
la requête si elle n’y est pas déjà. Les résultats finaux doivent être retournés dans l’ordre donné par la 
requête textuelle. 
Plus précisément, pour chaque résultat de la partie SQL (incluant donc une clé c de T) on parcourt les 
résultats de la requête textuelle pour chercher la clé c (si elle existe) et son score. Les résultats de la 
partie SQL qui retrouvent la clé dans les résultats de la requête textuelle sont retournés en ordre 
décroissant du score de pertinence textuelle (donc dans l’ordre fourni par la requête textuelle). 
Hypothèses : Nous considérons que les résultats d’une requête SQL sont potentiellement trop 
volumineux pour être gardés en mémoire, tandis que ceux des requêtes textuelles sont de taille 
raisonnable (ensembles de couples clé-score) et peuvent être stockés en mémoire. Nous considérons 
également que les résultats finaux des requêtes mixtes peuvent être stockés en mémoire. 
Remarque : La composition des résultats des deux requêtes dans le sens inverse (en prenant un par un 
les résultats de la requête textuelle et en vérifiant si la clé apparait dans le résultat de la partie SQL) 
aurait l’avantage de donner les résultats dans le bon ordre, mais nécessiterait la ré-exécution de la partie 
SQL pour chaque résultat de la partie textuelle (les résultats SQL ne pouvant pas être gardés en 
mémoire, conformément à l’hypothèse ci-dessus).  
2. On exécute d’abord la requête textuelle et pour chaque clé retournée par celle-ci on vérifie par une 
requête SQL si elle fait partie du résultat final ou non (si elle respecte la partie SQL de la requête). La 
partie SQL de la requête doit donc être modifiée pour inclure une condition sur la valeur de la clé de T. 
Il est demandé d’implémenter dans l’API de la BDe l’exécution de requêtes mixtes, en utilisant le 
premier type de plan, ensuite de réaliser une étude comparative entre les deux types de plans 
d’exécution. 
Pour implémenter dans la BDe le premier type de plan d’exécution, il faudra définir dans l’API les opérateurs 
suivants : 
✓ Un opérateur SQL, qui reçoit une requête SQL et l’exécute sur la BD relationnelle en utilisant JDBC.  
✓ Un opérateur textuel, qui reçoit une requête textuelle et l’exécute sur les documents du répertoire R. 
Les résultats contiennent le nom du document (clé de T) et son score de pertinence, et sont produits 
en ordre décroissant du score. 
✓ Un opérateur de jointure entre les résultats SQL et textuels pour le premier type de plan d’exécution. 
✓ Tout autre opérateur que vous jugerez nécessaire pour ce plan d’exécution. 
Le plan d’exécution est un arbre d’opérateurs, dont la racine produit les résultats de la requête. Chaque 
opérateur qui peut fonctionner en mode « pipleline » sera implémenté sous la forme d’un itérateur qui fournit 
deux méthodes : init() et next(). Il faut également que le plan d’exécution offre les mêmes deux opérateurs, 
init() et next(), qui permettent de produire le résultat finale élément par élément.  
L’étude comparative des deux types de plans doit inclure : 
✓ Le fonctionnement détaillé des opérateurs des deux types de plans. 
✓ Un comparatif des temps d’exécution des deux types de plan, en fonction du temps d’exécution et du 
nombre de résultats des parties SQL, respectivement textuelle de la requête.  
Les hypothèses supplémentaires suivantes sont considérées :  
7 
CY Cergy Paris Université, Master IISC 1ère Année                                                                    
Atelier de Gestion de Projet 
o Le temps d’exécution d’une requête SQL dans le premier plan est à peu près le même que le 
coût d’une requête textuelle, car cette dernière utilise un index construit sur disque. 
o Le temps d’exécution d’une requête SQL du deuxième plan est k fois plus faible que celui de 
la requête SQL du premier plan, car elle peut utiliser un index sur la clé.   
✓ Toute discussion argumentée sur des améliorations possibles dans les plans d’exécution pour 
diminuer le temps d’exécution dans les différents cas de figure. 
A faire 
✓ Spécifier l’API de la BDe : paquetages, classes, méthodes, etc. 
✓ Implémenter les opérations de l’API à l’aide de JDBC et de l’API Lucene (voir le squelette de 
programme fourni et la documentation générale https://lucene.apache.org/core/10_1_0/index.html) 
✓ L’étude comparative des deux types de plans 
数据库文件如下DROP TABLE IF EXISTS Arret_Transport;
DROP TABLE IF EXISTS Transport;
DROP TABLE IF EXISTS SiteTouristique;
DROP TABLE IF EXISTS Hotel;
DROP TABLE IF EXISTS Arret;
DROP TABLE IF EXISTS Lieu;
DROP TABLE IF EXISTS Ile;

CREATE TABLE Ile (
  ILE_id INT NOT NULL PRIMARY KEY,
  ILE_nom VARCHAR(100) NOT NULL
);


CREATE TABLE Lieu (
  LIE_id INT NOT NULL PRIMARY KEY,
  LIE_nom VARCHAR(100) NOT NULL,
  LIE_type ENUM('port','hotel','site_touristique','arret') NOT NULL,
  LIE_coordonnees POINT NOT NULL,  -- Utilisation du type géospatial POINT
  ILE_id INT NOT NULL,
  FOREIGN KEY (ILE_id) REFERENCES Ile (ILE_id) ON DELETE CASCADE,
  SPATIAL INDEX (LIE_coordonnees)  -- Index spatial pour accélérer les requêtes
);


CREATE TABLE Arret (
  ARR_id INT NOT NULL PRIMARY KEY,
  ARR_type_transport ENUM('bus','bateau') NOT NULL,
  LIE_id INT DEFAULT NULL,
  FOREIGN KEY (LIE_id) REFERENCES Lieu (LIE_id) ON DELETE SET NULL
);

CREATE TABLE Hotel (
  HOT_id INT NOT NULL PRIMARY KEY,
  HOT_etoiles INT DEFAULT NULL CHECK (HOT_etoiles BETWEEN 1 AND 5),
  HOT_tarif INT DEFAULT NULL,
  HOT_plage varchar(255) NOT NULL,
  LIE_id INT DEFAULT NULL,
  -- ARR_id INT NOT NULL,
  FOREIGN KEY (LIE_id) REFERENCES Lieu (LIE_id) ON DELETE SET NULL
  -- FOREIGN KEY (ARR_id) REFERENCES Arret (ARR_id) ON DELETE CASCADE
);

CREATE TABLE SiteTouristique (
  SIT_id INT NOT NULL PRIMARY KEY,
  SIT_description TEXT DEFAULT NULL,
  SIT_tarif INT DEFAULT NULL,
  SIT_duree INT DEFAULT NULL CHECK (SIT_duree > 0),
  SIT_type ENUM('historique','activite') NOT NULL,
  LIE_id INT DEFAULT NULL,
  -- ARR_id INT NOT NULL,
  FOREIGN KEY (LIE_id) REFERENCES Lieu (LIE_id) ON DELETE SET NULL
  -- FOREIGN KEY (ARR_id) REFERENCES Arret (ARR_id) ON DELETE CASCADE
);

CREATE TABLE Transport (
  TRP_id INT NOT NULL PRIMARY KEY,
  TRP_nom VARCHAR(255) NOT NULL,
  TRP_capacite INT NOT NULL,
  ILE_id INT NOT NULL,
  Tarif DECIMAL(10,2) DEFAULT NULL,
  vitesse INT DEFAULT NULL,
  type ENUM('Bus','Bateau') DEFAULT NULL,
  FOREIGN KEY (ILE_id) REFERENCES Ile (ILE_id) ON DELETE CASCADE
);

CREATE TABLE Arret_Transport (
  TRP_id INT NOT NULL,
  ARR_id INT NOT NULL,
  PRIMARY KEY (TRP_id, ARR_id),
  FOREIGN KEY (TRP_id) REFERENCES Transport (TRP_id) ON DELETE CASCADE,
  FOREIGN KEY (ARR_id) REFERENCES Arret (ARR_id) ON DELETE CASCADE
);



那么我该如何修正代码完成所有文档所需的测试